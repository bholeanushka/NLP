{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad90ced",
   "metadata": {},
   "source": [
    "# Text Pre-Processing (Stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d77dc2",
   "metadata": {},
   "source": [
    "#### This practice file is designed to provide a hands-on introduction to stemming, an essential preprocessing step in Natural Language Processing (NLP). \n",
    "\n",
    "1) Stemming: Stemming is the process of reducing words to their root form by stripping prefixes or suffixes. The root form may not always be a valid word, but it effectively groups similar words together for text processing tasks. For example: Running, runs, and ran → run\n",
    "\n",
    "\n",
    "2) Stemmer: A stemmer is an algorithm or tool used to perform stemming.\n",
    "\n",
    "\n",
    "3) Lemmatization: Often confused with stemming, lemmatization reduces words to their base form (lemma) by considering the word's meaning and grammatical structure. For example: Running → run (same as stemming) , Better → good (different from stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f112bd",
   "metadata": {},
   "source": [
    "## PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c28e81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc4fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run', 'runner', 'running', 'ran', 'runs', 'easily', 'fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99127ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77032337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run -> run\n",
      "runner -> runner\n",
      "running -> run\n",
      "ran -> ran\n",
      "runs -> run\n",
      "easily -> easili\n",
      "fairly -> fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + ' -> ' + stemming.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc6150",
   "metadata": {},
   "source": [
    "## RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d6fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ac43e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, remove common suffixes like 'ing', 'ed', 'ly', etc.\n",
    "stemmer = RegexpStemmer('ing$|er$|ly$|es$|s$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "410726de",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run', 'runner', 'running', 'ran', 'runs', 'easily', 'fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8918ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words: ['run', 'runner', 'running', 'ran', 'runs', 'easily', 'fairly']\n",
      "Stemmed Words: ['run', 'runn', 'runn', 'ran', 'run', 'easi', 'fair']\n"
     ]
    }
   ],
   "source": [
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "print(\"Original Words:\", words)\n",
    "print(\"Stemmed Words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e585a1a",
   "metadata": {},
   "source": [
    "## Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47b8cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7f2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballstemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d8b8b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run -> run\n",
      "runner -> runner\n",
      "running -> run\n",
      "ran -> ran\n",
      "runs -> run\n",
      "easily -> easili\n",
      "fairly -> fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + ' -> ' + snowballstemmer.stem(word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
